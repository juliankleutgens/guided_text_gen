train: lm1b
valid: lm1b
tokenizer_name_or_path: bert-base-uncased
cache_dir:  ~/hf_datasets_cache
path_to_data: /n/netscratch/dominici_lab/Lab/juliank/data/lm1b/1-billion-word-language-modeling-benchmark-r13output # https://www.statmt.org/lm-benchmark/
wrap: True
streaming: False
domain_fraction: 0.7 # fraction of src and 1-value for tgt domain
